{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.1.1-py3-none-any.whl (32 kB)\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.1.14-py3-none-any.whl (812 kB)\n",
      "\u001b[K     |████████████████████████████████| 812 kB 4.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting python-dotenv\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Collecting fastapi\n",
      "  Downloading fastapi-0.110.1-py3-none-any.whl (91 kB)\n",
      "\u001b[K     |████████████████████████████████| 91 kB 42.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting uvicorn[standard]\n",
      "  Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
      "\u001b[K     |████████████████████████████████| 60 kB 33.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting langserve\n",
      "  Downloading langserve-0.0.51-py3-none-any.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 21.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting langchainhub\n",
      "  Downloading langchainhub-0.1.15-py3-none-any.whl (4.6 kB)\n",
      "Collecting sse_starlette\n",
      "  Downloading sse_starlette-2.1.0-py3-none-any.whl (9.2 kB)\n",
      "Collecting httpx_sse\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Collecting slack_bolt\n",
      "  Downloading slack_bolt-1.18.1-py2.py3-none-any.whl (194 kB)\n",
      "\u001b[K     |████████████████████████████████| 194 kB 38.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pydantic==2.6.4\n",
      "  Downloading pydantic-2.6.4-py3-none-any.whl (394 kB)\n",
      "\u001b[K     |████████████████████████████████| 394 kB 14.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tiktoken<1,>=0.5.2\n",
      "  Downloading tiktoken-0.6.0-cp38-cp38-macosx_10_9_x86_64.whl (975 kB)\n",
      "\u001b[K     |████████████████████████████████| 975 kB 80.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting langchain-core<0.2.0,>=0.1.33\n",
      "  Downloading langchain_core-0.1.40-py3-none-any.whl (276 kB)\n",
      "\u001b[K     |████████████████████████████████| 276 kB 39.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting openai<2.0.0,>=1.10.0\n",
      "  Downloading openai-1.16.2-py3-none-any.whl (267 kB)\n",
      "\u001b[K     |████████████████████████████████| 267 kB 28.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting dataclasses-json<0.7,>=0.5.7\n",
      "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17\n",
      "  Downloading langsmith-0.1.40-py3-none-any.whl (87 kB)\n",
      "\u001b[K     |████████████████████████████████| 87 kB 47.2 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/lib/python3.8/site-packages (from langchain->-r requirements.txt (line 2)) (5.3.1)\n",
      "Collecting langchain-text-splitters<0.1,>=0.0.1\n",
      "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/anaconda3/lib/python3.8/site-packages (from langchain->-r requirements.txt (line 2)) (1.18.5)\n",
      "Collecting tenacity<9.0.0,>=8.1.0\n",
      "  Downloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3\n",
      "  Downloading aiohttp-3.9.3-cp38-cp38-macosx_10_9_x86_64.whl (399 kB)\n",
      "\u001b[K     |████████████████████████████████| 399 kB 99.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2 in /opt/anaconda3/lib/python3.8/site-packages (from langchain->-r requirements.txt (line 2)) (2.24.0)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0; python_version < \"3.11\"\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4\n",
      "  Downloading SQLAlchemy-2.0.29-cp38-cp38-macosx_10_9_x86_64.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 42.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting langchain-community<0.1,>=0.0.30\n",
      "  Downloading langchain_community-0.0.31-py3-none-any.whl (1.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.9 MB 27.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting starlette<0.38.0,>=0.37.2\n",
      "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
      "\u001b[K     |████████████████████████████████| 71 kB 2.9 MB/s s eta 0:00:01\n",
      "\u001b[?25hCollecting typing-extensions>=4.8.0\n",
      "  Downloading typing_extensions-4.11.0-py3-none-any.whl (34 kB)\n",
      "Collecting h11>=0.8\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 30.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: click>=7.0 in /opt/anaconda3/lib/python3.8/site-packages (from uvicorn[standard]->-r requirements.txt (line 5)) (7.1.2)\n",
      "Collecting watchfiles>=0.13; extra == \"standard\"\n",
      "  Downloading watchfiles-0.21.0-cp38-cp38-macosx_10_7_x86_64.whl (429 kB)\n",
      "\u001b[K     |████████████████████████████████| 429 kB 32.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting httptools>=0.5.0; extra == \"standard\"\n",
      "  Downloading httptools-0.6.1-cp38-cp38-macosx_10_9_x86_64.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 19.4 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting uvloop!=0.15.0,!=0.15.1,>=0.14.0; (sys_platform != \"win32\" and (sys_platform != \"cygwin\" and platform_python_implementation != \"PyPy\")) and extra == \"standard\"\n",
      "  Downloading uvloop-0.19.0-cp38-cp38-macosx_10_9_x86_64.whl (803 kB)\n",
      "\u001b[K     |████████████████████████████████| 803 kB 31.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting websockets>=10.4; extra == \"standard\"\n",
      "  Downloading websockets-12.0-cp38-cp38-macosx_10_9_x86_64.whl (121 kB)\n",
      "\u001b[K     |████████████████████████████████| 121 kB 38.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting httpx>=0.23.0\n",
      "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "\u001b[K     |████████████████████████████████| 75 kB 19.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting orjson>=2\n",
      "  Downloading orjson-3.10.0-cp38-cp38-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (251 kB)\n",
      "\u001b[K     |████████████████████████████████| 251 kB 46.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting types-requests<3.0.0.0,>=2.31.0.2\n",
      "  Downloading types_requests-2.31.0.20240406-py3-none-any.whl (15 kB)\n",
      "Collecting anyio\n",
      "  Downloading anyio-4.3.0-py3-none-any.whl (85 kB)\n",
      "\u001b[K     |████████████████████████████████| 85 kB 17.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting slack-sdk<4,>=3.25.0\n",
      "  Downloading slack_sdk-3.27.1-py2.py3-none-any.whl (285 kB)\n",
      "\u001b[K     |████████████████████████████████| 285 kB 110.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting annotated-types>=0.4.0\n",
      "  Using cached annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Collecting pydantic-core==2.16.3\n",
      "  Downloading pydantic_core-2.16.3-cp38-cp38-macosx_10_12_x86_64.whl (1.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.9 MB 17.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting regex>=2022.1.18\n",
      "  Downloading regex-2023.12.25-cp38-cp38-macosx_10_9_x86_64.whl (296 kB)\n",
      "\u001b[K     |████████████████████████████████| 296 kB 84.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting packaging<24.0,>=23.2\n",
      "  Using cached packaging-23.2-py3-none-any.whl (53 kB)\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/lib/python3.8/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai->-r requirements.txt (line 1)) (4.47.0)\n",
      "Collecting sniffio\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Collecting distro<2,>=1.7.0\n",
      "  Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0\n",
      "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
      "\u001b[K     |████████████████████████████████| 49 kB 32.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jsonpointer>=1.9\n",
      "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.5-cp38-cp38-macosx_10_9_x86_64.whl (30 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.9.4-cp38-cp38-macosx_10_9_x86_64.whl (83 kB)\n",
      "\u001b[K     |████████████████████████████████| 83 kB 11.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.4.1-cp38-cp38-macosx_10_9_x86_64.whl (55 kB)\n",
      "\u001b[K     |████████████████████████████████| 55 kB 19.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 2)) (19.3.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2->langchain->-r requirements.txt (line 2)) (1.25.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2->langchain->-r requirements.txt (line 2)) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2->langchain->-r requirements.txt (line 2)) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2->langchain->-r requirements.txt (line 2)) (2.10)\n",
      "Requirement already satisfied: greenlet!=0.4.17; platform_machine == \"aarch64\" or (platform_machine == \"ppc64le\" or (platform_machine == \"x86_64\" or (platform_machine == \"amd64\" or (platform_machine == \"AMD64\" or (platform_machine == \"win32\" or platform_machine == \"WIN32\"))))) in /opt/anaconda3/lib/python3.8/site-packages (from SQLAlchemy<3,>=1.4->langchain->-r requirements.txt (line 2)) (0.4.16)\n",
      "Collecting httpcore==1.*\n",
      "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 31.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting exceptiongroup>=1.0.2; python_version < \"3.11\"\n",
      "  Using cached exceptiongroup-1.2.0-py3-none-any.whl (16 kB)\n",
      "Collecting mypy-extensions>=0.3.0\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "\u001b[31mERROR: tiktoken 0.6.0 has requirement requests>=2.26.0, but you'll have requests 2.24.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: types-requests 2.31.0.20240406 has requirement urllib3>=2, but you'll have urllib3 1.25.9 which is incompatible.\u001b[0m\n",
      "Installing collected packages: regex, tiktoken, orjson, typing-extensions, annotated-types, pydantic-core, pydantic, langsmith, tenacity, jsonpointer, jsonpatch, packaging, langchain-core, sniffio, exceptiongroup, anyio, h11, httpcore, httpx, distro, openai, langchain-openai, mypy-extensions, typing-inspect, marshmallow, dataclasses-json, langchain-text-splitters, frozenlist, aiosignal, multidict, yarl, async-timeout, aiohttp, SQLAlchemy, langchain-community, langchain, python-dotenv, starlette, fastapi, watchfiles, httptools, uvloop, websockets, uvicorn, langserve, types-requests, langchainhub, sse-starlette, httpx-sse, slack-sdk, slack-bolt\n",
      "  Attempting uninstall: regex\n",
      "    Found existing installation: regex 2020.6.8\n",
      "    Uninstalling regex-2020.6.8:\n",
      "      Successfully uninstalled regex-2020.6.8\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 4.7.1\n",
      "    Uninstalling typing-extensions-4.7.1:\n",
      "      Successfully uninstalled typing-extensions-4.7.1\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 23.1\n",
      "    Uninstalling packaging-23.1:\n",
      "      Successfully uninstalled packaging-23.1\n",
      "  Attempting uninstall: SQLAlchemy\n",
      "    Found existing installation: SQLAlchemy 1.3.18\n",
      "    Uninstalling SQLAlchemy-1.3.18:\n",
      "      Successfully uninstalled SQLAlchemy-1.3.18\n",
      "Successfully installed SQLAlchemy-2.0.29 aiohttp-3.9.3 aiosignal-1.3.1 annotated-types-0.6.0 anyio-4.3.0 async-timeout-4.0.3 dataclasses-json-0.6.4 distro-1.9.0 exceptiongroup-1.2.0 fastapi-0.110.1 frozenlist-1.4.1 h11-0.14.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 httpx-sse-0.4.0 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.14 langchain-community-0.0.31 langchain-core-0.1.40 langchain-openai-0.1.1 langchain-text-splitters-0.0.1 langchainhub-0.1.15 langserve-0.0.51 langsmith-0.1.40 marshmallow-3.21.1 multidict-6.0.5 mypy-extensions-1.0.0 openai-1.16.2 orjson-3.10.0 packaging-23.2 pydantic-2.6.4 pydantic-core-2.16.3 python-dotenv-1.0.1 regex-2023.12.25 slack-bolt-1.18.1 slack-sdk-3.27.1 sniffio-1.3.1 sse-starlette-2.1.0 starlette-0.37.2 tenacity-8.2.3 tiktoken-0.6.0 types-requests-2.31.0.20240406 typing-extensions-4.11.0 typing-inspect-0.9.0 uvicorn-0.29.0 uvloop-0.19.0 watchfiles-0.21.0 websockets-12.0 yarl-1.9.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dotenv\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo-1106\", temperature=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I said \"J\\'adore la programmation\" which means \"I love programming\" in French.', response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 41, 'total_tokens': 62}, 'model_name': 'gpt-3.5-turbo-1106', 'system_fingerprint': 'fp_592ef5907d', 'finish_reason': 'stop', 'logprobs': None}, id='run-ab586035-558e-45d1-80c3-03bbcfce39f5-0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "chat.invoke(\n",
    "    [\n",
    "        HumanMessage(\n",
    "            content=\"Translate this sentence from English to French: I love programming.\"\n",
    "        ),\n",
    "        AIMessage(content=\"J'adore la programmation.\"),\n",
    "        HumanMessage(content=\"What did you just say?\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer all questions to the best of your ability.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I said \"J\\'adore la programmation\" which means \"I love programming\" in French.', response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 61, 'total_tokens': 82}, 'model_name': 'gpt-3.5-turbo-1106', 'system_fingerprint': 'fp_592ef5907d', 'finish_reason': 'stop', 'logprobs': None}, id='run-f281ef91-b9ab-4f85-8566-837c66f7ed13-0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(\n",
    "                content=\"Translate this sentence from English to French: I love programming.\"\n",
    "            ),\n",
    "            AIMessage(content=\"J'adore la programmation.\"),\n",
    "            HumanMessage(content=\"What did you just say?\"),\n",
    "        ],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hi!'), AIMessage(content='whats up?')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "demo_ephemeral_chat_history = ChatMessageHistory()\n",
    "\n",
    "demo_ephemeral_chat_history.add_user_message(\"hi!\")\n",
    "\n",
    "demo_ephemeral_chat_history.add_ai_message(\"whats up?\")\n",
    "\n",
    "demo_ephemeral_chat_history.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The translation of \"I love programming\" in French is \"J\\'adore la programmation.\"', response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 53, 'total_tokens': 73}, 'model_name': 'gpt-3.5-turbo-1106', 'system_fingerprint': 'fp_592ef5907d', 'finish_reason': 'stop', 'logprobs': None}, id='run-7fd9a49a-eb76-4aec-a0e2-d5fafc5bc3aa-0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_ephemeral_chat_history.add_user_message(\n",
    "    \"Translate this sentence from English to French: I love programming.\"\n",
    ")\n",
    "\n",
    "response = chain.invoke({\"messages\": demo_ephemeral_chat_history.messages})\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I said the translation of \"I love programming\" in French is \"J\\'adore la programmation.\"', response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 87, 'total_tokens': 109}, 'model_name': 'gpt-3.5-turbo-1106', 'system_fingerprint': 'fp_592ef5907d', 'finish_reason': 'stop', 'logprobs': None}, id='run-4928b31f-7ab5-42b1-81d5-37c02d214966-0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_ephemeral_chat_history.add_ai_message(response)\n",
    "\n",
    "demo_ephemeral_chat_history.add_user_message(\"What did you just say?\")\n",
    "\n",
    "chain.invoke({\"messages\": demo_ephemeral_chat_history.messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
